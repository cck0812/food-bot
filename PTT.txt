import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import time
#time.clock()
page = 7004
df = pd.DataFrame(columns=['文章標題','作者','發文時間','讚數','文章網址','文章內容'])
index = 0
useragent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'
headers = {'User-Agent':useragent}
for i in range(7004):  
    url = f'https://www.ptt.cc/bbs/Food/index{page}.html'
    try:
        res = requests.get(url,headers=headers)
        soup = BeautifulSoup(res.text,'html.parser')
        for i in soup.select('div[class="title"]'):
            try:
                title = i.text
                href = 'https://www.ptt.cc'+i.a['href']
                res = requests.get(href)
                soup = BeautifulSoup(res.text,'html.parser')
                author = soup.select('div[class="article-metaline"]')[0].text.split('作者')[1]
                post_time = soup.select('div[class="article-metaline"]')[2].text.split('時間')[1]
                if post_time > : 
                else 
                text = soup.select('div[id="main-content"]')[0].text.split(post_time)[1].split('--\n※ 發信站: 批踢踢實業坊(ptt.cc)')[0]
                push = len(soup.select('span[class="hl push-tag"]'))
                df.loc[index] = [title,author,post_time,push,href,text]
                print(title)
                index += 1
            except:
                pass
        page -= 1
    except Exception as e:
        print(e)

time.sleep(5)    
df.to_excel('ptt.xlsx',encoding='utf-16')
df.to_json('E:/ptt.json',orient='index',force_ascii=False)
#print('Processing time:',round(time.clock()/3600,2),'hrs')